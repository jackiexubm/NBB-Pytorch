{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "from torch.autograd import Variable as V\n",
    "from torchvision.models import vgg19\n",
    "import torchvision.transforms as transforms\n",
    "import numpy as np\n",
    "from PIL import Image"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### VGG also has a batch normalized version. The paper didn't specify if batch norm was used"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.cuda.set_device(0)\n",
    "\n",
    "vgg = vgg19(True).eval().cuda()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Prediction for hen.jpg is: 8\n",
      "Prediction for dog.jpg is: 207\n"
     ]
    }
   ],
   "source": [
    "preprocess = transforms.Compose([transforms.Resize(224),\n",
    "                                         transforms.ToTensor(),\n",
    "                                         transforms.Normalize(mean=[0.485, 0.456, 0.406],\n",
    "                                                              std=[0.229, 0.224, 0.225])])\n",
    "\n",
    "hen = Image.open(\"hen.jpg\")\n",
    "out = vgg(V(preprocess(hen).unsqueeze(0)).cuda())\n",
    "print('Prediction for hen.jpg is: %s'%(np.argmax(out.cpu().detach().numpy())))\n",
    "\n",
    "dog = Image.open(\"dog.jpg\")\n",
    "out = vgg(V(preprocess(dog).unsqueeze(0)).cuda())\n",
    "print('Prediction for dog.jpg is: %s'%(np.argmax(out.cpu().detach().numpy())))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### VGG is verified making correct predictions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Now let's extract the features pyramid (section 3.1)\n",
    "#### Check the VGG architecture"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "VGG(\n",
      "  (features): Sequential(\n",
      "    (0): Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (1): ReLU(inplace)\n",
      "    (2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (3): ReLU(inplace)\n",
      "    (4): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "    (5): Conv2d(64, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (6): ReLU(inplace)\n",
      "    (7): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (8): ReLU(inplace)\n",
      "    (9): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "    (10): Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (11): ReLU(inplace)\n",
      "    (12): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (13): ReLU(inplace)\n",
      "    (14): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (15): ReLU(inplace)\n",
      "    (16): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (17): ReLU(inplace)\n",
      "    (18): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "    (19): Conv2d(256, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (20): ReLU(inplace)\n",
      "    (21): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (22): ReLU(inplace)\n",
      "    (23): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (24): ReLU(inplace)\n",
      "    (25): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (26): ReLU(inplace)\n",
      "    (27): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "    (28): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (29): ReLU(inplace)\n",
      "    (30): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (31): ReLU(inplace)\n",
      "    (32): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (33): ReLU(inplace)\n",
      "    (34): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (35): ReLU(inplace)\n",
      "    (36): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "  )\n",
      "  (classifier): Sequential(\n",
      "    (0): Linear(in_features=25088, out_features=4096, bias=True)\n",
      "    (1): ReLU(inplace)\n",
      "    (2): Dropout(p=0.5)\n",
      "    (3): Linear(in_features=4096, out_features=4096, bias=True)\n",
      "    (4): ReLU(inplace)\n",
      "    (5): Dropout(p=0.5)\n",
      "    (6): Linear(in_features=4096, out_features=1000, bias=True)\n",
      "  )\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "print(vgg)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### We want the outputs of the first 5 ReLUs\n",
    "#### use hooks to extract them"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "feature_pyramid = []\n",
    "\n",
    "def extract_feature(self, input, output):\n",
    "    feature_pyramid.append(output)\n",
    "    print('Inside ' + self.__class__.__name__)\n",
    "    print('input size:', input[0].size())\n",
    "    print('output size:', output.data.size())\n",
    "\n",
    "layer_inds = [1, 3, 6, 8, 11]\n",
    "\n",
    "for layer_ind in layer_inds:\n",
    "    vgg.features[layer_ind].register_forward_hook(extract_feature)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Inside ReLU\n",
      "input size: torch.Size([1, 64, 224, 224])\n",
      "output size: torch.Size([1, 64, 224, 224])\n",
      "Inside ReLU\n",
      "input size: torch.Size([1, 64, 224, 224])\n",
      "output size: torch.Size([1, 64, 224, 224])\n",
      "Inside ReLU\n",
      "input size: torch.Size([1, 128, 112, 112])\n",
      "output size: torch.Size([1, 128, 112, 112])\n",
      "Inside ReLU\n",
      "input size: torch.Size([1, 128, 112, 112])\n",
      "output size: torch.Size([1, 128, 112, 112])\n",
      "Inside ReLU\n",
      "input size: torch.Size([1, 256, 56, 56])\n",
      "output size: torch.Size([1, 256, 56, 56])\n"
     ]
    }
   ],
   "source": [
    "feature_pyramid = []\n",
    "out = vgg(V(preprocess(dog).unsqueeze(0)).cuda())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "and those are the first 5 ReLU outputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
